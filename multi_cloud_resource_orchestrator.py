# -*- coding: utf-8 -*-
"""Multi-Cloud Resource Orchestrator

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y1sEyvWd3UiDWmKNrdVAn4E3hqiXSSDK
"""

# multi_cloud_orchestrator.py
# Standalone version - No external dependencies required

import json
import logging
from typing import Dict, List, Optional
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import random
from concurrent.futures import ThreadPoolExecutor
from time import sleep

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class CloudResource:
    provider: str
    resource_type: str
    resource_id: str
    region: str
    status: str
    tags: Dict[str, str]
    created_at: datetime

# Mock AWS API responses for demonstration
class MockAWSAPI:
    """Simulates AWS API responses without requiring boto3"""

    @staticmethod
    def generate_mock_ec2_instances(region: str, count: int = 5) -> List[Dict]:
        statuses = ['running', 'stopped', 'pending', 'terminated']
        instances = []

        for i in range(count):
            instance = {
                'InstanceId': f'i-{random.randint(100000000000, 999999999999):012x}',
                'InstanceType': random.choice(['t2.micro', 't2.small', 't3.medium', 'm5.large']),
                'State': {'Name': random.choice(statuses)},
                'LaunchTime': datetime.now() - timedelta(days=random.randint(1, 365)),
                'Tags': []
            }

            # Add tags to some instances
            if random.random() > 0.3:
                instance['Tags'] = [
                    {'Key': 'Environment', 'Value': random.choice(['Production', 'Development', 'Testing'])},
                    {'Key': 'Application', 'Value': random.choice(['WebServer', 'Database', 'API'])}
                ]

            instances.append(instance)

        return instances

    @staticmethod
    def generate_mock_s3_buckets(count: int = 8) -> List[Dict]:
        buckets = []
        prefixes = ['data', 'backup', 'logs', 'media', 'analytics', 'archive']

        for i in range(count):
            bucket = {
                'Name': f'{random.choice(prefixes)}-bucket-{random.randint(1000, 9999)}',
                'CreationDate': datetime.now() - timedelta(days=random.randint(30, 730))
            }
            buckets.append(bucket)

        return buckets

    @staticmethod
    def generate_mock_bucket_tags(bucket_name: str) -> List[Dict]:
        if random.random() > 0.4:
            return [
                {'Key': 'Project', 'Value': random.choice(['DataLake', 'Analytics', 'Backup'])},
                {'Key': 'Owner', 'Value': random.choice(['DevOps', 'DataTeam', 'Engineering'])}
            ]
        return []

class AWSManager:
    """Manages AWS resources - Standalone version using mock data"""

    def __init__(self, region: str = 'us-east-1'):
        self.region = region
        self.mock_api = MockAWSAPI()
        logger.info(f"Initialized AWS Manager for region: {region}")

    def list_ec2_instances(self) -> List[CloudResource]:
        """List EC2 instances in the region"""
        resources = []

        try:
            # Simulate API call delay
            sleep(0.5)

            # Get mock instances
            instances = self.mock_api.generate_mock_ec2_instances(self.region)

            for instance in instances:
                tags = {tag['Key']: tag['Value'] for tag in instance.get('Tags', [])}

                resources.append(CloudResource(
                    provider='AWS',
                    resource_type='EC2',
                    resource_id=instance['InstanceId'],
                    region=self.region,
                    status=instance['State']['Name'],
                    tags=tags,
                    created_at=instance['LaunchTime']
                ))

            logger.info(f"Found {len(resources)} EC2 instances in {self.region}")
        except Exception as e:
            logger.error(f"Error listing EC2 instances: {e}")

        return resources

    def list_s3_buckets(self) -> List[CloudResource]:
        """List S3 buckets (global service)"""
        resources = []

        try:
            # Simulate API call delay
            sleep(0.3)

            # Get mock buckets
            buckets = self.mock_api.generate_mock_s3_buckets()

            for bucket in buckets:
                tags_list = self.mock_api.generate_mock_bucket_tags(bucket['Name'])
                tags = {tag['Key']: tag['Value'] for tag in tags_list}

                resources.append(CloudResource(
                    provider='AWS',
                    resource_type='S3',
                    resource_id=bucket['Name'],
                    region='global',
                    status='active',
                    tags=tags,
                    created_at=bucket['CreationDate']
                ))

            logger.info(f"Found {len(resources)} S3 buckets")
        except Exception as e:
            logger.error(f"Error listing S3 buckets: {e}")

        return resources

    def create_ec2_instance(self, ami_id: str, instance_type: str, tags: Dict[str, str]) -> Optional[str]:
        """Create a new EC2 instance"""
        try:
            instance_id = f'i-{random.randint(100000000000, 999999999999):012x}'
            logger.info(f"Created EC2 instance: {instance_id} (type: {instance_type})")
            return instance_id
        except Exception as e:
            logger.error(f"Error creating EC2 instance: {e}")
            return None

    def terminate_ec2_instance(self, instance_id: str) -> bool:
        """Terminate an EC2 instance"""
        try:
            logger.info(f"Terminated EC2 instance: {instance_id}")
            return True
        except Exception as e:
            logger.error(f"Error terminating EC2 instance: {e}")
            return False

class MultiCloudOrchestrator:
    """Main orchestrator for multi-cloud resource management"""

    def __init__(self):
        self.aws_managers: Dict[str, AWSManager] = {}
        self.resource_cache: List[CloudResource] = []
        logger.info("Multi-Cloud Orchestrator initialized")

    def add_aws_region(self, region: str):
        """Add an AWS region to monitor"""
        self.aws_managers[region] = AWSManager(region)
        logger.info(f"Added AWS region: {region}")

    def discover_all_resources(self) -> List[CloudResource]:
        """Discover all resources across all configured regions"""
        all_resources = []

        logger.info("Starting resource discovery across all regions...")

        # Use ThreadPoolExecutor for parallel discovery
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = []

            # Submit discovery tasks for each region
            for region, manager in self.aws_managers.items():
                futures.append(executor.submit(manager.list_ec2_instances))

            # S3 is global, only query once
            if self.aws_managers:
                first_manager = list(self.aws_managers.values())[0]
                futures.append(executor.submit(first_manager.list_s3_buckets))

            # Collect results
            for future in futures:
                try:
                    resources = future.result()
                    all_resources.extend(resources)
                except Exception as e:
                    logger.error(f"Error in resource discovery: {e}")

        self.resource_cache = all_resources
        logger.info(f"Discovery complete. Total resources found: {len(all_resources)}")
        return all_resources

    def get_resource_summary(self) -> Dict:
        """Generate summary statistics of discovered resources"""
        summary = {
            'total_resources': len(self.resource_cache),
            'by_provider': {},
            'by_type': {},
            'by_region': {},
            'by_status': {}
        }

        for resource in self.resource_cache:
            # Count by provider
            summary['by_provider'][resource.provider] = \
                summary['by_provider'].get(resource.provider, 0) + 1

            # Count by type
            summary['by_type'][resource.resource_type] = \
                summary['by_type'].get(resource.resource_type, 0) + 1

            # Count by region
            summary['by_region'][resource.region] = \
                summary['by_region'].get(resource.region, 0) + 1

            # Count by status
            summary['by_status'][resource.status] = \
                summary['by_status'].get(resource.status, 0) + 1

        return summary

    def find_untagged_resources(self) -> List[CloudResource]:
        """Find resources without any tags"""
        return [r for r in self.resource_cache if not r.tags or len(r.tags) == 0]

    def find_stopped_instances(self) -> List[CloudResource]:
        """Find stopped EC2 instances"""
        return [r for r in self.resource_cache
                if r.resource_type == 'EC2' and r.status == 'stopped']

    def generate_cost_optimization_report(self) -> Dict:
        """Generate cost optimization recommendations"""
        untagged = self.find_untagged_resources()
        stopped = self.find_stopped_instances()

        report = {
            'total_findings': len(untagged) + len(stopped),
            'untagged_resources': len(untagged),
            'stopped_instances': len(stopped),
            'recommendations': [],
            'potential_monthly_savings_usd': 0.0
        }

        if untagged:
            report['recommendations'].append({
                'priority': 'MEDIUM',
                'type': 'untagged_resources',
                'count': len(untagged),
                'message': f'Found {len(untagged)} resources without tags. Add tags for better cost tracking.',
                'action': 'Add required tags: Environment, Project, Owner'
            })

        if stopped:
            # Estimate savings (avg $30/month per t2.small instance)
            estimated_savings = len(stopped) * 30.0
            report['potential_monthly_savings_usd'] = estimated_savings

            report['recommendations'].append({
                'priority': 'HIGH',
                'type': 'stopped_instances',
                'count': len(stopped),
                'message': f'Found {len(stopped)} stopped EC2 instances. Consider terminating unused instances.',
                'action': 'Review and terminate instances stopped for >30 days',
                'estimated_savings_usd': estimated_savings
            })

        # Check for old resources
        old_resources = [r for r in self.resource_cache
                        if (datetime.now() - r.created_at).days > 180]

        if old_resources:
            report['recommendations'].append({
                'priority': 'LOW',
                'type': 'old_resources',
                'count': len(old_resources),
                'message': f'Found {len(old_resources)} resources older than 6 months.',
                'action': 'Review if these resources are still needed'
            })

        return report

    def export_inventory(self, filename: str):
        """Export resource inventory to JSON file"""
        inventory = []

        for resource in self.resource_cache:
            inventory.append({
                'provider': resource.provider,
                'type': resource.resource_type,
                'id': resource.resource_id,
                'region': resource.region,
                'status': resource.status,
                'tags': resource.tags,
                'created_at': resource.created_at.isoformat(),
                'age_days': (datetime.now() - resource.created_at).days
            })

        with open(filename, 'w') as f:
            json.dump(inventory, f, indent=2)

        logger.info(f"Exported inventory to {filename}")
        print(f"\n✓ Inventory exported to: {filename}")

    def get_compliance_report(self) -> Dict:
        """Generate compliance report"""
        total = len(self.resource_cache)
        tagged = [r for r in self.resource_cache if r.tags]

        required_tags = ['Environment', 'Project', 'Owner']
        compliant = []

        for resource in self.resource_cache:
            if all(tag in resource.tags for tag in required_tags):
                compliant.append(resource)

        return {
            'total_resources': total,
            'tagged_resources': len(tagged),
            'tagging_compliance_percent': (len(tagged) / total * 100) if total > 0 else 0,
            'fully_compliant': len(compliant),
            'full_compliance_percent': (len(compliant) / total * 100) if total > 0 else 0,
            'required_tags': required_tags
        }

def main():
    """Main execution function"""
    print("=" * 70)
    print(" Multi-Cloud Resource Orchestrator - Standalone Demo")
    print("=" * 70)
    print()

    # Initialize orchestrator
    orchestrator = MultiCloudOrchestrator()

    # Add multiple regions
    print("📍 Adding AWS regions...")
    orchestrator.add_aws_region('us-east-1')
    orchestrator.add_aws_region('us-west-2')
    orchestrator.add_aws_region('eu-west-1')
    print()

    # Discover resources
    print("🔍 Discovering cloud resources...")
    resources = orchestrator.discover_all_resources()
    print(f"\n✓ Found {len(resources)} total resources")
    print()

    # Display resource summary
    print("=" * 70)
    print(" Resource Summary")
    print("=" * 70)
    summary = orchestrator.get_resource_summary()
    print(json.dumps(summary, indent=2))
    print()

    # Find untagged resources
    print("=" * 70)
    print(" Untagged Resources")
    print("=" * 70)
    untagged = orchestrator.find_untagged_resources()
    print(f"Found {len(untagged)} untagged resources:")
    for resource in untagged[:5]:  # Show first 5
        print(f"  - {resource.resource_type}: {resource.resource_id} ({resource.region})")
    if len(untagged) > 5:
        print(f"  ... and {len(untagged) - 5} more")
    print()

    # Generate cost optimization report
    print("=" * 70)
    print(" Cost Optimization Report")
    print("=" * 70)
    cost_report = orchestrator.generate_cost_optimization_report()
    print(json.dumps(cost_report, indent=2))
    print()

    # Compliance report
    print("=" * 70)
    print(" Compliance Report")
    print("=" * 70)
    compliance = orchestrator.get_compliance_report()
    print(json.dumps(compliance, indent=2))
    print()

    # Export inventory
    print("=" * 70)
    print(" Exporting Inventory")
    print("=" * 70)
    orchestrator.export_inventory('cloud_inventory.json')
    print()

    print("=" * 70)
    print(" Demo completed successfully!")
    print("=" * 70)

if __name__ == "__main__":
    main()